{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMI7CYxcyiUB"
   },
   "source": [
    "Before running the file Upload all your data set on your goole drive in a zip format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YjtnZQkTu6tX"
   },
   "outputs": [],
   "source": [
    "#Mount our google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4y_fGlmur4v"
   },
   "outputs": [],
   "source": [
    "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
    "#download and unzip the data from google drive Colab environment\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "#use only file id of the link\n",
    "#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n",
    "#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n",
    "url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n",
    "gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1f40EeRuvAkO"
   },
   "outputs": [],
   "source": [
    "#To get the average frame count \n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "#change the path accordingly\n",
    "video_files =  glob.glob('/content/Real videos/*.mp4')\n",
    "#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n",
    "#video_files += video_files1\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "  cap = cv2.VideoCapture(video_file)\n",
    "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
    "    video_files.remove(video_file)\n",
    "    continue\n",
    "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print(\"frames\" , frame_count)\n",
    "print(\"Total number of videos: \" , len(frame_count))\n",
    "print('Average frame per video:',np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U92Ovn3JvV52"
   },
   "outputs": [],
   "source": [
    "# to extract frame\n",
    "def frame_extract(path):\n",
    "  vidObj = cv2.VideoCapture(path) \n",
    "  success = 1\n",
    "  while success:\n",
    "      success, image = vidObj.read()\n",
    "      if success:\n",
    "          yield image\n",
    "!pip3 install face_recognition\n",
    "!mkdir '/content/drive/My Drive/FF_REAL_Face_only_data'\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.autonotebook import tqdm\n",
    "# process the frames\n",
    "def create_face_videos(path_list,out_dir):\n",
    "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
    "  print(\"No of videos already present \" , len(already_present_count))\n",
    "  for path in tqdm(path_list):\n",
    "    out_path = os.path.join(out_dir,path.split('/')[-1])\n",
    "    file_exists = glob.glob(out_path)\n",
    "    if(len(file_exists) != 0):\n",
    "      print(\"File Already exists: \" , out_path)\n",
    "      continue\n",
    "    frames = []\n",
    "    flag = 0\n",
    "    face_all = []\n",
    "    frames1 = []\n",
    "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
    "    for idx,frame in enumerate(frame_extract(path)):\n",
    "      #if(idx % 3 == 0):\n",
    "      if(idx <= 150):\n",
    "        frames.append(frame)\n",
    "        if(len(frames) == 4):\n",
    "          faces = face_recognition.batch_face_locations(frames)\n",
    "          for i,face in enumerate(faces):\n",
    "            if(len(face) != 0):\n",
    "              top,right,bottom,left = face[0]\n",
    "            try:\n",
    "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
    "            except:\n",
    "              pass\n",
    "          frames = []\n",
    "    try:\n",
    "      del top,right,bottom,left\n",
    "    except:\n",
    "      pass\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sF5qiWGLvei-"
   },
   "outputs": [],
   "source": [
    "create_face_videos(video_files,'/content/drive/My Drive/FF_REAL_Face_only_data/')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
